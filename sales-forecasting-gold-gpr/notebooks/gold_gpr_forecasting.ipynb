{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Price Forecasting with Geopolitical Risk\n",
    "## Time-Series Forecasting using XGBoost\n",
    "\n",
    "This notebook builds a forecasting model for next-day gold prices using:\n",
    "- Historical gold and silver prices\n",
    "- Geopolitical risk indices (GPRD, GPRD_ACT, GPRD_THREAT)\n",
    "- Engineered features: lags, rolling statistics, calendar features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "DATA_RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "OUTPUTS_PLOTS_DIR = BASE_DIR / \"outputs\" / \"plots\"\n",
    "OUTPUTS_FORECASTS_DIR = BASE_DIR / \"outputs\" / \"forecasts\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "\n",
    "OUTPUTS_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_FORECASTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_RAW_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Metal Data Collection\n",
    "\n",
    "Fetch all 8 metals from FRED (Gold, Silver, Platinum, Palladium) and MetalPriceAPI (Copper, Aluminum, Nickel, Zinc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MULTI-METAL DATA COLLECTION\n",
    "# ==============================================================================\n",
    "\n",
    "import requests\n",
    "from fredapi import Fred\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# API Keys\n",
    "FRED_API_KEY = 'your_fred_api_key_here'  # Get from: https://fred.stlouisfed.org/docs/api/api_key.html\n",
    "METALPRICEAPI_KEY = 'd4f1bd88c9f54564527ab0779e1157ef'\n",
    "\n",
    "# Initialize FRED\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# ==============================================================================\n",
    "# METAL CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "METAL_CONFIG = {\n",
    "    # Precious metals from FRED (full historical data 2015-2026)\n",
    "    'GOLD': {'source': 'fred', 'series_id': 'GOLDAMGBD228NLBM'},\n",
    "    'SILVER': {'source': 'fred', 'series_id': 'SILVERPRICE'},\n",
    "    'PLATINUM': {'source': 'fred', 'series_id': 'DPLATINUMUSD'},\n",
    "    'PALLADIUM': {'source': 'fred', 'series_id': 'DPALLADIUMUSD'},\n",
    "\n",
    "    # Industrial metals from MetalPriceAPI (2025-06-19 onwards)\n",
    "    'COPPER': {'source': 'metalpriceapi', 'symbol': 'XCU'},\n",
    "    'ALUMINUM': {'source': 'metalpriceapi', 'symbol': 'ALU'},\n",
    "    'NICKEL': {'source': 'metalpriceapi', 'symbol': 'NI'},\n",
    "    'ZINC': {'source': 'metalpriceapi', 'symbol': 'ZNC'}\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# DATA FETCHING FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def fetch_metalpriceapi_timeframe(symbols, start_date, end_date, api_key):\n",
    "    \"\"\"\n",
    "    Fetch historical metal prices from MetalPriceAPI.\n",
    "    Max 365 days per request.\n",
    "    \"\"\"\n",
    "    base_url = 'https://api.metalpriceapi.com/v1/timeframe'\n",
    "\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'base': 'USD',\n",
    "        'currencies': ','.join(symbols)\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get('success'):\n",
    "            rates_dict = data['rates']\n",
    "            df = pd.DataFrame.from_dict(rates_dict, orient='index')\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.sort_index(inplace=True)\n",
    "\n",
    "            # Convert from rate to price (invert)\n",
    "            df = 1 / df\n",
    "\n",
    "            return df\n",
    "        else:\n",
    "            error_msg = data.get('error', {}).get('info', 'Unknown error')\n",
    "            print(f\"API Error: {error_msg}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching MetalPriceAPI data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def fetch_all_metals_data(start_date='2015-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Fetch all metals from both FRED and MetalPriceAPI.\n",
    "    Returns combined DataFrame with all metal prices.\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    # FRED metals (full history)\n",
    "    print('=' * 60)\n",
    "    print('FETCHING FRED DATA (Gold, Silver, Platinum, Palladium)')\n",
    "    print('=' * 60)\n",
    "\n",
    "    for metal, config in METAL_CONFIG.items():\n",
    "        if config['source'] == 'fred':\n",
    "            try:\n",
    "                print(f\"Fetching {metal}... \", end='')\n",
    "                series = fred.get_series(\n",
    "                    config['series_id'],\n",
    "                    observation_start=start_date,\n",
    "                    observation_end=end_date\n",
    "                )\n",
    "                df_all[f'{metal}_PRICE'] = series\n",
    "                print(f\"\\u2713 {len(series)} records\")\n",
    "                time.sleep(0.5)  # Rate limiting\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\u2717 Error: {e}\")\n",
    "\n",
    "    # MetalPriceAPI metals (limited history)\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('FETCHING METALPRICEAPI DATA (Copper, Aluminum, Nickel, Zinc)')\n",
    "    print('=' * 60)\n",
    "    print('Note: Free tier data starts from 2025-06-19')\n",
    "\n",
    "    metalpriceapi_symbols = [\n",
    "        config['symbol'] for metal, config in METAL_CONFIG.items()\n",
    "        if config['source'] == 'metalpriceapi'\n",
    "    ]\n",
    "\n",
    "    # MetalPriceAPI free tier limitation\n",
    "    metalpriceapi_start = '2025-06-19'\n",
    "\n",
    "    if metalpriceapi_symbols:\n",
    "        print(f\"Fetching {len(metalpriceapi_symbols)} metals... \", end='')\n",
    "        df_metalapi = fetch_metalpriceapi_timeframe(\n",
    "            metalpriceapi_symbols,\n",
    "            metalpriceapi_start,\n",
    "            end_date,\n",
    "            METALPRICEAPI_KEY\n",
    "        )\n",
    "\n",
    "        if not df_metalapi.empty:\n",
    "            # Rename columns\n",
    "            symbol_to_name = {\n",
    "                config['symbol']: metal\n",
    "                for metal, config in METAL_CONFIG.items()\n",
    "                if config['source'] == 'metalpriceapi'\n",
    "            }\n",
    "            df_metalapi.columns = [f\"{symbol_to_name[col]}_PRICE\" for col in df_metalapi.columns]\n",
    "\n",
    "            # Merge with main dataframe\n",
    "            df_all = df_all.join(df_metalapi, how='outer')\n",
    "            print(f\"\\u2713 {len(df_metalapi)} records\")\n",
    "        else:\n",
    "            print('\\u2717 Failed')\n",
    "\n",
    "    # Sort by date\n",
    "    df_all.sort_index(inplace=True)\n",
    "\n",
    "    # Forward fill missing values (weekends, holidays)\n",
    "    df_all.ffill(inplace=True)\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXECUTE DATA COLLECTION\n",
    "# ==============================================================================\n",
    "\n",
    "print('Starting multi-metal data collection...')\n",
    "print(f\"Date range: 2015-01-01 to {datetime.now().strftime('%Y-%m-%d')}\\n\")\n",
    "\n",
    "df_metals_raw = fetch_all_metals_data(start_date='2015-01-01')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('DATA COLLECTION SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f\"Total records: {len(df_metals_raw)}\")\n",
    "print(f\"Date range: {df_metals_raw.index.min()} to {df_metals_raw.index.max()}\")\n",
    "print(f\"Metals collected: {len(df_metals_raw.columns)}\")\n",
    "print(f\"\\nColumns:\\n{list(df_metals_raw.columns)}\")\n",
    "print(f\"\\nMissing values per metal:\")\n",
    "print(df_metals_raw.isnull().sum())\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_metals_raw.head())\n",
    "\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(df_metals_raw.tail())\n",
    "\n",
    "# Save raw data\n",
    "import os\n",
    "os.makedirs(str(BASE_DIR / 'data'), exist_ok=True)\n",
    "output_path = str(BASE_DIR / 'data' / 'all_metals_raw.csv')\n",
    "df_metals_raw.to_csv(output_path)\n",
    "print(f\"\\n\\u2713 Raw data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopolitical Risk Data (GPRD)\n",
    "\n",
    "Add geopolitical risk indices from FRED and combine with metal price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ADD GEOPOLITICAL RISK DATA\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('ADDING GEOPOLITICAL RISK DATA (GPRD)')\n",
    "print('=' * 60)\n",
    "\n",
    "# Fetch GPRD data\n",
    "gprd_series_ids = {\n",
    "    'GPRD': 'GEPUCURRENT',\n",
    "    'GPRD_ACT': 'GPDACT',\n",
    "    'GPRD_THREAT': 'GPDTHAT'\n",
    "}\n",
    "\n",
    "df_gprd = pd.DataFrame()\n",
    "\n",
    "for name, series_id in gprd_series_ids.items():\n",
    "    try:\n",
    "        print(f\"Fetching {name}... \", end='')\n",
    "        series = fred.get_series(\n",
    "            series_id,\n",
    "            observation_start='2015-01-01',\n",
    "            observation_end=datetime.now().strftime('%Y-%m-%d')\n",
    "        )\n",
    "        df_gprd[name] = series\n",
    "        print(f\"\\u2713 {len(series)} records\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\u2717 Error: {e}\")\n",
    "\n",
    "# Combine metals + GPRD\n",
    "df_combined = df_metals_raw.join(df_gprd, how='left')\n",
    "df_combined.ffill(inplace=True)\n",
    "df_combined.bfill(inplace=True)\n",
    "\n",
    "print(f\"\\n\\u2713 Combined dataset shape: {df_combined.shape}\")\n",
    "print(f\"Columns: {list(df_combined.columns)}\")\n",
    "\n",
    "# Save combined data\n",
    "output_path = str(BASE_DIR / 'data' / 'metals_gprd_combined.csv')\n",
    "df_combined.to_csv(output_path)\n",
    "print(f\"\\u2713 Combined data saved to: {output_path}\")\n",
    "\n",
    "# Use this for the rest of the analysis\n",
    "df = df_combined.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - All Metals\n",
    "\n",
    "Create lag features, rolling statistics, time-based features, and target variables for all 8 metals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE ENGINEERING - ALL METALS\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('FEATURE ENGINEERING FOR ALL METALS')\n",
    "print('=' * 60)\n",
    "\n",
    "df_feat = df.copy()\n",
    "\n",
    "# Define which metals we have\n",
    "METAL_NAMES = ['GOLD', 'SILVER', 'PLATINUM', 'PALLADIUM', 'COPPER', 'ALUMINUM', 'NICKEL', 'ZINC']\n",
    "GPRD_NAMES = ['GPRD', 'GPRD_ACT', 'GPRD_THREAT']\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LAG FEATURES (for each metal)\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n1. Creating lag features...')\n",
    "lag_periods = [1, 2, 3, 5, 10]\n",
    "\n",
    "for metal in METAL_NAMES:\n",
    "    price_col = f'{metal}_PRICE'\n",
    "    if price_col in df_feat.columns:\n",
    "        for lag in lag_periods:\n",
    "            df_feat[f'{metal}_LAG_{lag}'] = df_feat[price_col].shift(lag)\n",
    "        print(f\"  \\u2713 {metal}: {len(lag_periods)} lag features\")\n",
    "\n",
    "# GPRD lags\n",
    "for gprd in GPRD_NAMES:\n",
    "    if gprd in df_feat.columns:\n",
    "        for lag in lag_periods:\n",
    "            df_feat[f'{gprd}_LAG_{lag}'] = df_feat[gprd].shift(lag)\n",
    "        print(f\"  \\u2713 {gprd}: {len(lag_periods)} lag features\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ROLLING STATISTICS (for each metal)\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n2. Creating rolling statistics...')\n",
    "windows = [5, 10, 20, 30]\n",
    "\n",
    "for metal in METAL_NAMES:\n",
    "    price_col = f'{metal}_PRICE'\n",
    "    if price_col in df_feat.columns:\n",
    "        for window in windows:\n",
    "            df_feat[f'{metal}_ROLL_MEAN_{window}'] = df_feat[price_col].rolling(window).mean()\n",
    "            df_feat[f'{metal}_ROLL_STD_{window}'] = df_feat[price_col].rolling(window).std()\n",
    "        print(f\"  \\u2713 {metal}: {len(windows) * 2} rolling features\")\n",
    "\n",
    "# GPRD rolling stats\n",
    "for gprd in GPRD_NAMES:\n",
    "    if gprd in df_feat.columns:\n",
    "        for window in windows:\n",
    "            df_feat[f'{gprd}_ROLL_MEAN_{window}'] = df_feat[gprd].rolling(window).mean()\n",
    "            df_feat[f'{gprd}_ROLL_STD_{window}'] = df_feat[gprd].rolling(window).std()\n",
    "        print(f\"  \\u2713 {gprd}: {len(windows) * 2} rolling features\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TIME-BASED FEATURES\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n3. Creating time-based features...')\n",
    "df_feat['YEAR'] = df_feat.index.year\n",
    "df_feat['MONTH'] = df_feat.index.month\n",
    "df_feat['QUARTER'] = df_feat.index.quarter\n",
    "df_feat['DAYOFWEEK'] = df_feat.index.dayofweek\n",
    "df_feat['DAYOFYEAR'] = df_feat.index.dayofyear\n",
    "print('  \\u2713 5 time features')\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TARGET VARIABLES (next-day price for each metal)\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n4. Creating target variables...')\n",
    "for metal in METAL_NAMES:\n",
    "    price_col = f'{metal}_PRICE'\n",
    "    if price_col in df_feat.columns:\n",
    "        df_feat[f'{metal}_TARGET'] = df_feat[price_col].shift(-1)\n",
    "        print(f\"  \\u2713 {metal}_TARGET\")\n",
    "\n",
    "# Drop rows with NaN (from lag/rolling/target operations)\n",
    "initial_rows = len(df_feat)\n",
    "df_feat.dropna(inplace=True)\n",
    "final_rows = len(df_feat)\n",
    "\n",
    "print(f\"\\n\\u2713 Feature engineering complete!\")\n",
    "print(f\"  Rows dropped (NaN): {initial_rows - final_rows}\")\n",
    "print(f\"  Final dataset shape: {df_feat.shape}\")\n",
    "print(f\"  Total features: {df_feat.shape[1]}\")\n",
    "\n",
    "# Save feature-engineered data\n",
    "output_path = str(BASE_DIR / 'data' / 'metals_features_engineered.csv')\n",
    "df_feat.to_csv(output_path)\n",
    "print(f\"\\u2713 Feature data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Models for Each Metal\n",
    "\n",
    "Train individual XGBoost models for each of the 8 metals and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TRAIN INDIVIDUAL MODELS FOR EACH METAL\n",
    "# ==============================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('TRAINING XGBOOST MODELS FOR ALL METALS')\n",
    "print('=' * 60)\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(str(MODELS_DIR), exist_ok=True)\n",
    "os.makedirs(str(BASE_DIR / 'outputs'), exist_ok=True)\n",
    "\n",
    "# Store model performance\n",
    "model_performance = {}\n",
    "\n",
    "# Columns to exclude from features (raw prices, targets, GPRD raw)\n",
    "exclude_cols = ['GOLD_PRICE', 'SILVER_PRICE', 'PLATINUM_PRICE', 'PALLADIUM_PRICE',\n",
    "                'COPPER_PRICE', 'ALUMINUM_PRICE', 'NICKEL_PRICE', 'ZINC_PRICE',\n",
    "                'GPRD', 'GPRD_ACT', 'GPRD_THREAT',\n",
    "                'GOLD_TARGET', 'SILVER_TARGET', 'PLATINUM_TARGET', 'PALLADIUM_TARGET',\n",
    "                'COPPER_TARGET', 'ALUMINUM_TARGET', 'NICKEL_TARGET', 'ZINC_TARGET']\n",
    "\n",
    "# Train model for each metal\n",
    "for metal in METAL_NAMES:\n",
    "    target_col = f'{metal}_TARGET'\n",
    "\n",
    "    # Check if we have data for this metal\n",
    "    if target_col not in df_feat.columns:\n",
    "        print(f\"\\n\\u2717 Skipping {metal}: No data available\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"TRAINING MODEL: {metal}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Prepare features and target\n",
    "    feature_cols = [col for col in df_feat.columns if col not in exclude_cols]\n",
    "\n",
    "    X = df_feat[feature_cols]\n",
    "    y = df_feat[target_col]\n",
    "\n",
    "    # Remove rows where target is NaN\n",
    "    valid_idx = y.notna()\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "\n",
    "    print(f\"Dataset size: {len(X)} samples, {len(feature_cols)} features\")\n",
    "\n",
    "    # Train/test split (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    # Train XGBoost model\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print('Training model... ', end='')\n",
    "    model.fit(X_train, y_train)\n",
    "    print('\\u2713 Done')\n",
    "\n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"\\nPerformance:\")\n",
    "    print(f\"  Train RMSE: ${train_rmse:.2f}\")\n",
    "    print(f\"  Test RMSE:  ${test_rmse:.2f}\")\n",
    "    print(f\"  Train MAE:  ${train_mae:.2f}\")\n",
    "    print(f\"  Test MAE:   ${test_mae:.2f}\")\n",
    "\n",
    "    # Store performance\n",
    "    model_performance[metal] = {\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'n_samples': len(X),\n",
    "        'n_features': len(feature_cols)\n",
    "    }\n",
    "\n",
    "    # Save model\n",
    "    model_path = str(MODELS_DIR / f'{metal.lower()}_xgb_model.pkl')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"\\u2713 Model saved: {model_path}\")\n",
    "\n",
    "    # Save feature columns for this model\n",
    "    feature_cols_path = str(MODELS_DIR / f'{metal.lower()}_feature_cols.pkl')\n",
    "    joblib.dump(feature_cols, feature_cols_path)\n",
    "    print(f\"\\u2713 Feature columns saved: {feature_cols_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# MODEL PERFORMANCE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('MODEL PERFORMANCE SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "if model_performance:\n",
    "    performance_df = pd.DataFrame(model_performance).T\n",
    "    performance_df = performance_df.round(2)\n",
    "    print(performance_df)\n",
    "\n",
    "    # Save performance summary\n",
    "    perf_path = str(BASE_DIR / 'outputs' / 'model_performance_all_metals.csv')\n",
    "    performance_df.to_csv(perf_path)\n",
    "    print(f\"\\n\\u2713 Performance summary saved to: {perf_path}\")\n",
    "else:\n",
    "    print('No models were trained (no data available).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = DATA_RAW_DIR / \"Gold-Silver-GeopoliticalRisk_HistoricalData.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip().upper() for c in df.columns]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date and clean data\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values('DATE').set_index('DATE')\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['GOLD_PRICE', 'SILVER_PRICE', 'GPRD', 'GPRD_ACT', 'GPRD_THREAT']]\n",
    "\n",
    "# Forward fill then backward fill missing values\n",
    "df = df.ffill().bfill()\n",
    "\n",
    "print(f\"\\nData after cleaning:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold & Silver time series\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df.index, df['GOLD_PRICE'], label='Gold', alpha=0.8)\n",
    "plt.plot(df.index, df['SILVER_PRICE'], label='Silver', alpha=0.8)\n",
    "plt.title(\"Gold & Silver Spot Prices (1985\u20132025)\", fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"gold_silver_timeseries.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopolitical Risk Index\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(df.index, df['GPRD'], color='crimson', alpha=0.8)\n",
    "plt.title(\"Geopolitical Risk Index (GPRD)\", fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('GPRD')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"gprd_timeseries.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", center=0, fmt='.2f')\n",
    "plt.title(\"Correlation Matrix\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"corr_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target: next-day GOLD_PRICE\n",
    "df['GOLD_TARGET'] = df['GOLD_PRICE'].shift(-1)\n",
    "\n",
    "print(f\"Target variable created: GOLD_TARGET\")\n",
    "print(f\"First few values: {df['GOLD_TARGET'].head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "lags = [1, 2, 5, 10, 20]\n",
    "\n",
    "for lag in lags:\n",
    "    df[f'GOLD_LAG_{lag}'] = df['GOLD_PRICE'].shift(lag)\n",
    "    df[f'SILVER_LAG_{lag}'] = df['SILVER_PRICE'].shift(lag)\n",
    "    df[f'GPRD_LAG_{lag}'] = df['GPRD'].shift(lag)\n",
    "\n",
    "print(f\"\\nLag features created for lags: {lags}\")\n",
    "print(f\"New columns: {[c for c in df.columns if 'LAG' in c][:6]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling features\n",
    "windows = [5, 10, 20]\n",
    "\n",
    "for window in windows:\n",
    "    df[f'GOLD_ROLL_MEAN_{window}'] = df['GOLD_PRICE'].rolling(window).mean()\n",
    "    df[f'GOLD_ROLL_STD_{window}'] = df['GOLD_PRICE'].rolling(window).std()\n",
    "    df[f'GPRD_ROLL_MEAN_{window}'] = df['GPRD'].rolling(window).mean()\n",
    "\n",
    "print(f\"\\nRolling features created for windows: {windows}\")\n",
    "print(f\"New columns: {[c for c in df.columns if 'ROLL' in c][:6]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df['YEAR'] = df.index.year\n",
    "df['MONTH'] = df.index.month\n",
    "df['DAYOFWEEK'] = df.index.dayofweek\n",
    "\n",
    "print(f\"\\nTime-based features created: YEAR, MONTH, DAYOFWEEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "print(f\"\\nBefore dropping NaNs: {df.shape}\")\n",
    "df_model = df.dropna().copy()\n",
    "print(f\"After dropping NaNs: {df_model.shape}\")\n",
    "print(f\"Rows dropped: {len(df) - len(df_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split: train on data before 2020, validate on 2020+\n",
    "cutoff_date = \"2020-01-01\"\n",
    "\n",
    "train = df_model[df_model.index < cutoff_date]\n",
    "val = df_model[df_model.index >= cutoff_date]\n",
    "\n",
    "feature_cols = [c for c in df_model.columns if c != 'GOLD_TARGET']\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['GOLD_TARGET']\n",
    "X_val = val[feature_cols]\n",
    "y_val = val['GOLD_TARGET']\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, period: {train.index.min()} to {train.index.max()}\")\n",
    "print(f\"Validation set: {X_val.shape}, period: {val.index.min()} to {val.index.max()}\")\n",
    "print(f\"\\nNumber of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: Naive forecast (today's price as tomorrow's forecast)\n",
    "y_val_naive = val['GOLD_PRICE']\n",
    "y_val_naive = y_val_naive.reindex(y_val.index)\n",
    "\n",
    "rmse_naive = np.sqrt(mean_squared_error(y_val, y_val_naive))\n",
    "mae_naive = mean_absolute_error(y_val, y_val_naive)\n",
    "\n",
    "print(f\"Naive Baseline (today's price):\")\n",
    "print(f\"  RMSE: {rmse_naive:.2f}\")\n",
    "print(f\"  MAE: {mae_naive:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2: 5-day moving average\n",
    "df_model['GOLD_MA_5'] = df_model['GOLD_PRICE'].rolling(5).mean()\n",
    "val_ma = df_model.loc[y_val.index, 'GOLD_MA_5']\n",
    "\n",
    "rmse_ma = np.sqrt(mean_squared_error(y_val, val_ma))\n",
    "mae_ma = mean_absolute_error(y_val, val_ma)\n",
    "\n",
    "print(f\"\\n5-Day Moving Average Baseline:\")\n",
    "print(f\"  RMSE: {rmse_ma:.2f}\")\n",
    "print(f\"  MAE: {mae_ma:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = mean_absolute_error(y_val, y_val_pred)\n",
    "mape = np.mean(np.abs((y_val - y_val_pred) / y_val)) * 100\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nXGBoost Model Performance:\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  MAE: {mae:.2f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "print(f\"  R\u00b2: {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nImprovement over baselines:\")\n",
    "print(f\"  vs Naive: {((rmse_naive - rmse) / rmse_naive * 100):.1f}% reduction in RMSE\")\n",
    "print(f\"  vs 5-day MA: {((rmse_ma - rmse) / rmse_ma * 100):.1f}% reduction in RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_val.index, y_val, label=\"Actual\", alpha=0.8, linewidth=1.5)\n",
    "plt.plot(y_val.index, y_val_pred, label=\"Predicted (XGBoost)\", alpha=0.8, linewidth=1.5)\n",
    "plt.title(f\"Gold Price \u2013 Actual vs Predicted (RMSE={rmse:.2f}, R\u00b2={r2:.4f})\", fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Gold Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"gold_actual_vs_predicted_xgb.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = xgb_model.feature_importances_\n",
    "fi = pd.Series(importances, index=feature_cols).sort_values(ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "fi.sort_values().plot(kind=\"barh\", color='steelblue')\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\", fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"feature_importance_xgb.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "residuals = y_val - y_val_pred\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residual Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_PLOTS_DIR / \"residual_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model and Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = MODELS_DIR / \"gold_xgb_model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecasts\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"DATE\": y_val.index,\n",
    "    \"GOLD_ACTUAL\": y_val.values,\n",
    "    \"GOLD_PREDICTED\": y_val_pred\n",
    "})\n",
    "\n",
    "forecast_path = OUTPUTS_FORECASTS_DIR / \"gold_val_forecasts_xgb.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "\n",
    "print(f\"Forecasts saved to: {forecast_path}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature columns for later use\n",
    "feature_info = {\n",
    "    'feature_cols': feature_cols,\n",
    "    'metrics': {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'mape': mape,\n",
    "        'r2': r2\n",
    "    }\n",
    "}\n",
    "\n",
    "feature_path = MODELS_DIR / \"feature_info.pkl\"\n",
    "with open(feature_path, \"wb\") as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "\n",
    "print(f\"Feature info saved to: {feature_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. Loaded and cleaned gold, silver, and geopolitical risk data\n",
    "2. Created engineered features (lags, rolling stats, calendar features)\n",
    "3. Built baseline models for comparison\n",
    "4. Trained an XGBoost model to predict next-day gold prices\n",
    "5. Evaluated model performance with multiple metrics\n",
    "6. Visualized results and feature importance\n",
    "7. Saved the trained model and forecasts\n",
    "\n",
    "Next steps:\n",
    "- Run the Streamlit app for interactive exploration\n",
    "- Consider hyperparameter tuning\n",
    "- Explore SHAP values for model interpretability\n",
    "- Test on different time periods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}